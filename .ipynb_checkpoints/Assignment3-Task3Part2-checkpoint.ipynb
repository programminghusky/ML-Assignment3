{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "from os.path import dirname, join as pjoin\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.linalg as la\n",
    "from statistics import mean \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load heart data into arr\n",
    "heart_data_dir= \"heart.mat\"\n",
    "heart_data = sio.loadmat(heart_data_dir)\n",
    "arr = heart_data['dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the labels describing presence or absence of disease\n",
    "labels = heart_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSubsetScore(arr, labels):   \n",
    "    # instantiate the model\n",
    "    logreg = LogisticRegression(solver=\"liblinear\", C=0.303)\n",
    "    trainScores = [0]*10\n",
    "    testScores = [0]*10\n",
    "    nTrain = 200\n",
    "    nTest = 70\n",
    "    #repeating 10 times inside for loop\n",
    "    for i in range(0,10):\n",
    "        #Resetting the default random number generator with a new random seed \n",
    "        random.seed(i+1)\n",
    "        \n",
    "        #initialize randomMatrix from original matrix\n",
    "        randomArr = arr.copy()\n",
    "        randomLabels = labels.copy();\n",
    "\n",
    "        #randomize by swapping rows in random Matrix's randomArr and randomLabels\n",
    "        randomIndices = list(range(0,270))\n",
    "        random.shuffle(randomIndices)\n",
    "        for j in range(0,270):            \n",
    "            temp = randomArr[j]\n",
    "            randomArr[j] = randomArr[randomIndices[j]]\n",
    "            randomArr[randomIndices[j]] = temp\n",
    "            \n",
    "            temp = randomLabels[j]\n",
    "            randomLabels[j] = randomLabels[randomIndices[j]]\n",
    "            randomLabels[randomIndices[j]] = temp\n",
    "        #First 200 for training    \n",
    "        trainingArr = randomArr[range(0,nTrain),:]     \n",
    "        trainingLabels = randomLabels[range(0,nTrain)]\n",
    "        \n",
    "        #remaining 70 for testing\n",
    "        testingArr = randomArr[range(nTrain, nTrain+nTest),:]    \n",
    "        testingLabels = randomLabels[range(nTrain, nTrain+nTest)].ravel()\n",
    "        \n",
    "        #Training using logistic regression\n",
    "        logreg.fit(trainingArr,trainingLabels.ravel())\n",
    "        \n",
    "        #prediction on the training set\n",
    "        y_pred_train=logreg.predict(trainingArr)\n",
    "        #prediction on the test set\n",
    "        y_pred_test=logreg.predict(testingArr)\n",
    "        \n",
    "        nTrainCorrect = 0        \n",
    "        for j in range(0,nTrain):\n",
    "            #if predicted value is equal to the actual value increase the count\n",
    "            if y_pred_train[j] == trainingLabels[j]:\n",
    "                nTrainCorrect= nTrainCorrect + 1\n",
    "        #storing the prediction accuracy         \n",
    "        trainScores[i] = nTrainCorrect/nTrain\n",
    "        \n",
    "        nTestCorrect = 0        \n",
    "        for j in range(0,nTest):\n",
    "            #if predicted value is equal to the actual value increase the count\n",
    "            if y_pred_test[j] == testingLabels[j]:\n",
    "                nTestCorrect = nTestCorrect +1\n",
    "        #storing the prediction accuracy\n",
    "        testScores[i] = nTestCorrect/nTest\n",
    "    \n",
    "    #finding mean of training scores for 10 passes\n",
    "    trainScoresMean = mean(trainScores)\n",
    "    #finding mean of testing scores for 10 passes\n",
    "    testScoresMean = mean(testScores)\n",
    "    return [trainScoresMean, testScoresMean]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314285714285714\n",
      "[2, 9, 1, 4, 10, 7, 6, 3, 5, 11, 0, 12, 8]\n"
     ]
    }
   ],
   "source": [
    "k=13\n",
    "scoreBest = 0\n",
    "selectedFeatures = []\n",
    "allIndices = list(range(0,13))\n",
    "for i in range(0,1000):\n",
    "    random.seed(i+1)\n",
    "    selectedIndices = random.sample(allIndices, k)\n",
    "    trialFeatures = arr[:,selectedIndices]\n",
    "    trainScore, testScore = featureSubsetScore(trialFeatures, labels)\n",
    "    if testScore >scoreBest:\n",
    "        scoreBest = testScore\n",
    "        selectedFeatures = selectedIndices\n",
    "print(scoreBest) \n",
    "print(selectedFeatures)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
